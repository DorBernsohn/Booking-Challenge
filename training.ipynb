{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/DorBernsohn/Booking-Challenge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/Booking-Challenge')\n",
    "\n",
    "# train_path = Path(r\"/content/Booking-Challenge/data/train_set.csv\")\n",
    "# test_path = Path(r\"/content/Booking-Challenge/data/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# internal\n",
    "from utils import (load_data,\n",
    "                   extract_features,\n",
    "                   build_time_features,\n",
    "                   build_prev_city,\n",
    "                   build_first_city,\n",
    "                   split_features_label,\n",
    "                   flatten_features,\n",
    "                   LabelEncoderMapping)\n",
    "from config import train_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_data(train_path, min_trip_length_threshold=4)\n",
    "df_test = load_data(test_path, min_trip_length_threshold=4)\n",
    "data = pd.concat([df_train, df_test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df = extract_features(df)\n",
    "features, labels = split_features_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "features = features[features.utrip_id.isin(labels[labels.city_id != 0].utrip_id.values)]\n",
    "labels = labels[labels.city_id != 0]\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = features.set_index(['utrip_id', features.groupby('utrip_id').cumcount()])\n",
    "\n",
    "mux = pd.MultiIndex.from_product(df1.index.levels, names=df1.index.names)\n",
    "df2 = df1.reindex(mux, fill_value=1).reset_index(level=1, drop=True).reset_index()\n",
    "embeded_features = df2.groupby(['utrip_id']).agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dict_slices = tf.data.Dataset.from_tensor_slices((embeded_features.loc[:, ~embeded_features.columns.isin(['utrip_id', 'user_id', 'city_id', 'length'])].to_dict('list'), \\\n",
    "                                                  labels['city_id_encode'].values)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = embeded_features.loc[:, ~embeded_features.columns.isin(['utrip_id', 'user_id', 'city_id', 'length'])].keys()\r\n",
    "\r\n",
    "emb_map = {}\r\n",
    "for key in keys:\r\n",
    "  len_set_feature = max(set([st for row in embeded_features[key] for st in row])) + 1\r\n",
    "  emb_map[key]  = (len_set_feature, [int(len_set_feature/4) + 4 if len_set_feature > 4 else len_set_feature][0])\r\n",
    "emb_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {key: tf.keras.layers.Input(shape=(47), name=key) for key in embeded_features.loc[:, ~embeded_features.columns.isin(['utrip_id', 'user_id', 'city_id', 'length'])].keys()}\n",
    "\n",
    "embeddings = []\n",
    "for a, key in enumerate(inputs):\n",
    "    emb = tf.keras.layers.Embedding(emb_map[key][0], 20, name=f'embedding_{key}')(inputs[key])\n",
    "    embeddings.append(emb)\n",
    "h = tf.keras.layers.Concatenate()(embeddings)\n",
    "h = tf.keras.layers.Flatten()(h)\n",
    "h = tf.keras.layers.Dense(1028, activation='relu')(h)\n",
    "h = tf.keras.layers.Dropout(0.5)(h)\n",
    "h = tf.keras.layers.Dense(2048, activation='relu')(h)\n",
    "h = tf.keras.layers.Dropout(0.5)(h)\n",
    "h = tf.keras.layers.Dense(4096, activation='relu')(h)\n",
    "h = tf.keras.layers.Dense(max(labels['city_id_encode'].values) + 1, activation='softmax')(h) # len(list(set([st for row in embeded_features['city_id'] for st in row])))\n",
    "\n",
    "model_func = tf.keras.Model(inputs=inputs, outputs=h)\n",
    "model_func.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy(k=4)])\n",
    "model_func.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, label in dict_slices.take(1):\n",
    "  print(row)\n",
    "  print('-'*4)\n",
    "  print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_all_length = [i for i,_ in enumerate(dict_slices)][-1] + 1\n",
    "\n",
    "train_size = int(0.8 * labeled_all_length)\n",
    "val_test_size = int(0.1 * labeled_all_length)\n",
    "\n",
    "df_train = dict_slices.take(train_size)\n",
    "df_test = dict_slices.skip(train_size)\n",
    "df_val = df_test.skip(val_test_size)\n",
    "df_test = df_test.take(val_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func.fit(df_train, validation_data=df_val, epochs=20)"
   ]
  }
 ]
}